import OpenAI from 'openai';
import pino from 'pino';
import { Message } from './session';

const logger = pino({ name: 'conversational-agent' });

// Prompt sp√©cialis√© pour l'agent conversationnel
export const CONVERSATIONAL_SYSTEM_INSTRUCTIONS = `Tu es Bruno, assistant chantier super sympa ! üòä Ta mission est UNIQUEMENT la communication naturelle et l'exp√©rience utilisateur.

üéØ TON R√îLE :
- Communication naturelle et amicale avec les ouvriers
- Poser UNE question √† la fois, claire et cibl√©e
- Utiliser des emojis pour rendre l'√©change plus chaleureux
- Faire des r√©capitulatifs clairs quand n√©cessaire
- Demander "ok" pour confirmer les commandes

üí¨ TON STYLE :
- Ton amical et encourageant
- Tutoiement naturel
- Emojis appropri√©s (üèóÔ∏è üì¶ ‚è∞ ‚úÖ etc.)
- Messages courts et directs
- Langage simple, pas technique

üìã TES RESPONSABILIT√âS :
1. Accueillir chaleureusement les utilisateurs
2. Poser des questions pour obtenir les infos manquantes :
   - Nom du chantier
   - Mat√©riau(x) n√©cessaire(s) avec quantit√©s et unit√©s
   - Date et heure de besoin
3. Faire un r√©capitulatif clair avant confirmation
4. Demander confirmation avec "ok" uniquement

‚ùå CE QUE TU NE FAIS PAS :
- Tu ne t'occupes PAS d'extraire ou structurer les donn√©es
- Tu ne fais PAS de parsing ou d'analyse technique
- Tu ne valides PAS les formats (dates, heures, quantit√©s)
- Tu restes dans ton r√¥le de communication uniquement

üîÑ M√âTHODE DE TRAVAIL :
1. Si info manquante ‚Üí pose UNE question cibl√©e
2. Si plusieurs infos manquent ‚Üí priorise la plus importante
3. Quand tu as tout ‚Üí r√©capitule clairement
4. Demande confirmation avec "Pour confirmer, r√©ponds juste 'ok'"

IMPORTANT : Tu communiques naturellement mais tu laisses un autre syst√®me s'occuper de l'extraction et du stockage des donn√©es. Concentre-toi sur l'exp√©rience utilisateur !`;

export interface ConversationalResponse {
  message: string;
  confidence: number;
  processingTime: number;
  requiresFollowUp: boolean;
}

export class ConversationalAgent {
  private client: OpenAI;
  private model: string;

  constructor() {
    const apiKey = process.env['OPENAI_API_KEY'];
    if (!apiKey) {
      throw new Error('OPENAI_API_KEY environment variable is required');
    }

    this.client = new OpenAI({
      apiKey
    });

    this.model = process.env['OPENAI_MODEL'] || 'gpt-4o-mini';
    logger.info({ model: this.model }, 'ConversationalAgent initialized');
  }

  /**
   * Construit le contexte de conversation √† partir de l'historique
   */
  private buildConversationContext(userText: string, history: Message[]): string {
    let context = '';
    
    // Ajouter l'historique r√©cent (derniers 10 messages max)
    if (history.length > 0) {
      context += 'Historique de la conversation :\n';
      const recentHistory = history.slice(-10);
      for (const msg of recentHistory) {
        const role = msg.role === 'user' ? 'Utilisateur' : 'Assistant';
        context += `${role}: ${msg.content}\n`;
      }
      context += '\n';
    }
    
    context += `Message actuel de l'utilisateur: ${userText}`;
    return context;
  }

  /**
   * Calcule un score de confiance bas√© sur la r√©ponse g√©n√©r√©e
   */
  private calculateConfidence(response: string, _userText: string): number {
    let confidence = 0.7; // Base confidence

    // Augmenter la confiance si la r√©ponse contient des √©l√©ments positifs
    if (response.includes('r√©capitulatif') || response.includes('R√©capitulatif')) confidence += 0.1;
    if (response.includes('ok') && response.includes('confirmer')) confidence += 0.15;
    if (response.match(/[üòäüèóÔ∏èüì¶‚è∞‚úÖ]/)) confidence += 0.05;
    
    // Diminuer si la r√©ponse semble g√©n√©rique ou trop longue
    if (response.length > 500) confidence -= 0.1;
    if (response.includes('je ne peux pas') || response.includes('d√©sol√©')) confidence -= 0.2;

    return Math.min(Math.max(confidence, 0.1), 1.0);
  }

  /**
   * D√©termine si une r√©ponse de suivi est n√©cessaire
   */
  private requiresFollowUp(response: string, _userText: string): boolean {
    // Si on demande une confirmation avec "ok"
    if (response.includes('r√©ponds juste "ok"') || response.includes('r√©ponds simplement "ok"')) {
      return true;
    }
    
    // Si on pose une question
    if (response.includes('?')) {
      return true;
    }
    
    // Si on dit "Commande pr√™te √† √™tre transmise"
    if (response.includes('pr√™te √† √™tre transmise') || response.includes('transmise')) {
      return false;
    }

    return false;
  }

  /**
   * G√©n√®re une r√©ponse conversationnelle naturelle
   */
  async respond(
    userText: string,
    history: Message[] = []
  ): Promise<ConversationalResponse> {
    const startTime = Date.now();
    
    try {
      const context = this.buildConversationContext(userText, history);
      
      logger.info({
        model: this.model,
        contextLength: context.length,
        historyLength: history.length,
        userTextLength: userText.length
      }, 'Generating conversational response');

      const response = await this.client.responses.create({
        model: this.model,
        instructions: CONVERSATIONAL_SYSTEM_INSTRUCTIONS,
        input: context
      });

      const responseText = response.output_text;
      const processingTime = Date.now() - startTime;
      const confidence = this.calculateConfidence(responseText, userText);
      const requiresFollowUp = this.requiresFollowUp(responseText, userText);

      logger.info({
        responseLength: responseText.length,
        processingTime,
        confidence,
        requiresFollowUp,
        requestId: response.id || 'unknown'
      }, 'Conversational response generated');

      return {
        message: responseText,
        confidence,
        processingTime,
        requiresFollowUp
      };

    } catch (error) {
      const processingTime = Date.now() - startTime;
      
      logger.error({
        error: error instanceof Error ? error.message : 'Unknown error',
        model: this.model,
        processingTime
      }, 'Error generating conversational response');
      
      // R√©ponse de fallback sympathique
      return {
        message: 'üòÖ D√©sol√©, j\'ai eu un petit probl√®me technique. Peux-tu r√©p√©ter ta demande ?',
        confidence: 0.1,
        processingTime,
        requiresFollowUp: true
      };
    }
  }
}

// Instance singleton
export const conversationalAgent = new ConversationalAgent();